#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import json, sys, pathlib, re
from collections import defaultdict

# ì‚¬ìš©ë²•: catalog_compare_local.py hib.json fly.json out_dir

NON_DIFFS = {
  "type_alias": {
    "varchar": {"character varying"},
    "float8": {"double precision"},
    "timestamp": {"timestamp without time zone", "timestamp(0)"},
    "timestamptz": {"timestamp with time zone"},
  }
}

def _type_eq(a, b):
  a, b = (a or "").lower(), (b or "").lower()
  if a == b: return True
  for base, aliases in NON_DIFFS["type_alias"].items():
    if a == base and b in aliases: return True
    if b == base and a in aliases: return True
  return False

def _key(*parts): return ".".join(parts)
def load(path): return json.loads(pathlib.Path(path).read_text(encoding="utf-8"))
def index_by_table(items):
  m = defaultdict(list)
  for it in items:
    m[(it["table_schema"], it["table_name"])].append(it)
  return m

def normalize_names_ok(name):
  return bool(re.fullmatch(r"[a-z0-9_]+", (name or "")))

def compare(hib, fly):
  reasons = []

  hib_tables = {(t["table_schema"], t["table_name"]) for t in hib["tables"]}
  fly_tables = {(t["table_schema"], t["table_name"]) for t in fly["tables"]}

  only_hib = sorted(hib_tables - fly_tables)
  only_fly = sorted(fly_tables - hib_tables)
  if only_hib:
    reasons.append(f"Flywayì— ì—†ëŠ” í…Œì´ë¸”: {only_hib}")
  if only_fly:
    reasons.append(f"Hibernateì— ì—†ëŠ” í…Œì´ë¸”: {only_fly}")

  hib_cols = index_by_table(hib["columns"])
  fly_cols = index_by_table(fly["columns"])
  for tbl in sorted(hib_tables & fly_tables):
    a_cols = {c["column_name"]: c for c in hib_cols.get(tbl, [])}
    b_cols = {c["column_name"]: c for c in fly_cols.get(tbl, [])}
    for c in sorted(set(a_cols) - set(b_cols)):
      reasons.append(f"{tbl} ì»¬ëŸ¼ {c} ê°€ Flywayì— ì—†ìŒ")
    for c in sorted(set(b_cols) - set(a_cols)):
      reasons.append(f"{tbl} ì»¬ëŸ¼ {c} ê°€ Hibernateì— ì—†ìŒ")
    for c in sorted(set(a_cols) & set(b_cols)):
      ac, bc = a_cols[c], b_cols[c]
      if not _type_eq(ac.get("norm_type"), bc.get("norm_type")):
        reasons.append(f"{tbl}.{c} íƒ€ì… ë¶ˆì¼ì¹˜: {ac.get('norm_type')} vs {bc.get('norm_type')}")
      if bool(ac.get("is_nullable")) != bool(bc.get("is_nullable")):
        reasons.append(f"{tbl}.{c} NULL í—ˆìš© ë¶ˆì¼ì¹˜: {ac.get('is_nullable')} vs {bc.get('is_nullable')}")
      adef = 1 if (ac.get("column_default") or "").strip() else 0
      bdef = 1 if (bc.get("column_default") or "").strip() else 0
      if adef != bdef:
        reasons.append(f"{tbl}.{c} DEFAULT ìœ ë¬´ ë¶ˆì¼ì¹˜")

  def _keyset(rows, kind):
    out = defaultdict(set)
    for r in rows:
      if r["contype"] != kind: continue
      k = (r["table_schema"], r["table_name"])
      out[k].add(tuple(r["columns"] or []))
    return out

  hib_cons = hib["constraints"]; fly_cons = fly["constraints"]
  for kind, tag in (("p","PK"),("u","UNIQUE")):
    a = _keyset(hib_cons, kind); b = _keyset(fly_cons, kind)
    for tbl in sorted((set(a) | set(b))):
      if a[tbl] != b[tbl]:
        reasons.append(f"{tbl} {tag} ì§‘í•© ë¶ˆì¼ì¹˜: {sorted(a[tbl])} vs {sorted(b[tbl])}")

  def _fkset(rows):
    out = defaultdict(set)
    for r in rows:
      k = (r["table_schema"], r["table_name"])
      out[k].add( (tuple(r["columns"] or []), (r["ref_table_schema"], r["ref_table_name"]), tuple(r["ref_columns"] or [])) )
    return out
  a_fk = _fkset(hib["fkeys"]); b_fk = _fkset(fly["fkeys"])
  for tbl in sorted((set(a_fk) | set(b_fk))):
    if a_fk[tbl] != b_fk[tbl]:
      reasons.append(f"{tbl} FK ì§‘í•© ë¶ˆì¼ì¹˜")

  match = "yes" if not reasons else "no"
  return match, reasons

def suggestions_for_fly(fly):
  sug = []
  idx_by_tbl = index_by_table(fly["indexes"])
  fk_by_tbl = index_by_table(fly["fkeys"])
  for tbl, fks in fk_by_tbl.items():
    tbl_cols_index_sets = { tuple(i["columns"]) for i in idx_by_tbl.get(tbl, []) }
    for fk in fks:
      cols = tuple(fk["columns"] or [])
      if cols and cols not in tbl_cols_index_sets:
        sug.append(f"{tbl} FK {cols}ì— ë³´ì¡° ì¸ë±ìŠ¤ ìƒì„±ì„ ê²€í† í•˜ì„¸ìš” (ì¡°ì¸/ì‚­ì œ ì„±ëŠ¥).")
  cons_by_tbl = index_by_table(fly["constraints"])
  cols_by_tbl = index_by_table(fly["columns"])
  for tbl, cols in cols_by_tbl.items():
    pk_sets = [set(c["columns"] or []) for c in cons_by_tbl.get(tbl, []) if c.get("contype")=="p"]
    if not pk_sets:
      sug.append(f"{tbl}ì— ê¸°ë³¸í‚¤(PK)ê°€ ì—†ìŠµë‹ˆë‹¤. ID ì „ëµ/ìì—°í‚¤ ì—¬ë¶€ë¥¼ ëª…í™•íˆ í•˜ì„¸ìš”.")
    else:
      pk = next(iter(pk_sets))
      for c in cols:
        if c["column_name"] in pk and c.get("is_nullable"):
          sug.append(f"{tbl}.{c['column_name']}ëŠ” PKì¸ë° NULL í—ˆìš©ì…ë‹ˆë‹¤. NOT NULLë¡œ ê³ ì •í•˜ì„¸ìš”.")
  for t in fly["tables"]:
    if not normalize_names_ok(t["table_name"]):
      sug.append(f"{(t['table_schema'], t['table_name'])} ì´ë¦„ì„ snake_caseë¡œ ì •ë¦¬í•˜ì„¸ìš”.")
  for c in fly["columns"]:
    if not normalize_names_ok(c["column_name"]):
      sug.append(f"{(c['table_schema'], c['table_name'])}.{c['column_name']} ì»¬ëŸ¼ëª…ì„ snake_caseë¡œ ì •ë¦¬í•˜ì„¸ìš”.")
  for con in fly["constraints"]:
    if not normalize_names_ok(con["constraint_name"]):
      sug.append(f"{(con['table_schema'], con['table_name'])} ì œì•½ëª… `{con['constraint_name']}` ë„¤ì´ë° ì»¨ë²¤ì…˜ ì •ë¹„(pk_/fk_/uq_ ë“±).")
  for ix in fly["indexes"]:
    if not normalize_names_ok(ix["index_name"]):
      sug.append(f"{(ix['table_schema'], ix['table_name'])} ì¸ë±ìŠ¤ëª… `{ix['index_name']}` ë„¤ì´ë° ì»¨ë²¤ì…˜ ì •ë¹„(idx_<table>__<cols>).")
  for c in fly["columns"]:
    tn = (c.get("norm_type") or "").lower()
    nm = (c["column_name"] or "").lower()
    if nm in {"created_date","updated_date","created_at","updated_at"} and tn == "timestamp":
      sug.append(f"{(c['table_schema'], c['table_name'])}.{c['column_name']}ì— timestamptz ì‚¬ìš©ì„ ê²€í† í•˜ì„¸ìš”(íƒ€ì„ì¡´ ì•ˆì „).")
  for c in fly["columns"]:
    if (c.get("norm_type") or "").lower() == "varchar" and not c.get("character_maximum_length"):
      sug.append(f"{(c['table_schema'], c['table_name'])}.{c['column_name']} VARCHAR ê¸¸ì´ ë¯¸ì§€ì •. TEXT ë˜ëŠ” ëª…ì‹œì  ê¸¸ì´ ì „ëµì„ í™•ì •í•˜ì„¸ìš”.")

  out=[]; seen=set()
  for s in sug:
    if s not in seen:
      out.append(s); seen.add(s)
    if len(out) >= 10: break
  if not out:
    out.append("ìŠ¤í‚¤ë§ˆëŠ” ì–‘í˜¸í•©ë‹ˆë‹¤. ë§ˆì´ê·¸ë ˆì´ì…˜ íŠ¸ëœì­ì…˜/ë¡¤ë°± ì „ëµì„ ì •ê¸° ì ê²€í•˜ì„¸ìš”.")
  return out

def main():
  if len(sys.argv) != 4:
    print("usage: catalog_compare_local.py <hib.json> <fly.json> <out_dir>", file=sys.stderr)
    sys.exit(2)
  hib_path, fly_path, out_dir = sys.argv[1], sys.argv[2], sys.argv[3]
  hib = load(hib_path); fly = load(fly_path)

  match, reasons = compare(hib, fly)
  sugg = suggestions_for_fly(fly)

  result = {"match": match, "reasons": reasons, "suggestions": sugg}
  out_dir_p = pathlib.Path(out_dir); out_dir_p.mkdir(parents=True, exist_ok=True)
  (out_dir_p / "local_schema_compare.json").write_text(json.dumps(result, ensure_ascii=False, indent=2), encoding="utf-8")
  (out_dir_p / "ai_verdict.txt").write_text(f"{match}\n", encoding="utf-8")

  md = [f"# Local ìŠ¤í‚¤ë§ˆ ë¹„êµ ê²°ê³¼", f"- ê²°ê³¼(match): **{match.upper()}**", ""]
  if match == "no":
    md.append("## âŒ ì°¨ì´ ì‚¬ìœ ")
    for i, r in enumerate(reasons, 1): md.append(f"{i}. {r}")
  else:
    md.append("## âœ… ë…¼ë¦¬ì ìœ¼ë¡œ ë™ì¼í•œ ìŠ¤í‚¤ë§ˆë¡œ íŒë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
  md.append(""); md.append("## ğŸ”§ ê°œì„  ì œì•ˆ (Flyway DDL)")
  for i, s in enumerate(sugg, 1): md.append(f"{i}. {s}")
  (out_dir_p / "schema-compare-summary.md").write_text("\n".join(md), encoding="utf-8")

  print(f"Local compare done: {match}")

if __name__ == "__main__":
  main()
